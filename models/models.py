import subprocess
import sys

try:
    from efficientnet_pytorch import EfficientNet
except ImportError:
    print("ğŸ“¦ efficientnet_pytorch íŒ¨í‚¤ì§€ê°€ ì—†ì–´ì„œ ì„¤ì¹˜í•©ë‹ˆë‹¤...")
    subprocess.check_call([sys.executable, "-m", "pip", "install", "efficientnet_pytorch"])
    from efficientnet_pytorch import EfficientNet

try:
    import timm
except ImportError:
    print("ğŸ“¦ timm íŒ¨í‚¤ì§€ê°€ ì—†ì–´ì„œ ì„¤ì¹˜í•©ë‹ˆë‹¤...")    
    subprocess.check_call([sys.executable, "-m", "pip", "install", "timm"])
    import timm



import torch.nn as nn
# from efficientnet_pytorch import EfficientNet
from transformers import ViTForImageClassification, ViTFeatureExtractor
import torch
import torch.nn.functional as F
import gc
from torchvision import models
import torchvision.ops as ops
import collections


# íŒŒì´ì¬ ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ì‹¤í–‰: ë” ì´ìƒ ì°¸ì¡°ë˜ì§€ ì•ŠëŠ” ê°ì²´ë“¤ì„ ì •ë¦¬í•©ë‹ˆë‹¤.
gc.collect()

# CUDA ë©”ëª¨ë¦¬ ìºì‹œ ë¹„ìš°ê¸°: ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” GPU ë©”ëª¨ë¦¬ë¥¼ í•´ì œí•©ë‹ˆë‹¤.
torch.cuda.empty_cache()


def enet(model_name='efficientb0', num_classes=23):
    if model_name == 'efficientb0':
        return EfficientNet.from_pretrained('efficientnet-b0', num_classes=num_classes)
    elif model_name == 'efficientb1':
        return EfficientNet.from_pretrained('efficientnet-b1', num_classes=num_classes)
    elif model_name == 'efficientb2':
        return EfficientNet.from_pretrained('efficientnet-b2', num_classes=num_classes)
    elif model_name == 'efficientb3':
        return EfficientNet.from_pretrained('efficientnet-b3', num_classes=num_classes)
    elif model_name == 'efficientb4':
        return EfficientNet.from_pretrained('efficientnet-b4', num_classes=num_classes)
    elif model_name == 'efficientb5':
        return EfficientNet.from_pretrained('efficientnet-b5', num_classes=num_classes)
    elif model_name == 'efficientb6':
        return EfficientNet.from_pretrained('efficientnet-b6', num_classes=num_classes)
    elif model_name == 'efficientb7':
        return EfficientNet.from_pretrained('efficientnet-b7', num_classes=num_classes)
    else:
        raise ValueError('Invalid model name')


def convnext(num_classes=23):
    model = timm.create_model('convnext_base', pretrained=True)
    in_features = model.head.fc.in_features
    model.head.fc = nn.Linear(in_features, num_classes)
    return model


def convnext_tiny(num_classes=23):
    model = timm.create_model('convnext_tiny', pretrained=True)
    in_features = model.head.fc.in_features
    model.head.fc = nn.Linear(in_features, num_classes)
    return model


def vit(num_classes=23):
    model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224', num_labels=num_classes, ignore_mismatched_sizes=True)
    feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224')
    return model, feature_extractor


def swin_transformer(num_classes=23):
    model = timm.create_model('swin_base_patch4_window7_224', pretrained=True)
    in_features = model.num_features
    model.head = nn.Linear(in_features, num_classes)
    return model


def swin_transformer_tiny(num_classes=23):
    model = timm.create_model('swin_tiny_patch4_window7_224', pretrained=True)
    in_features = model.num_features
    model.head = nn.Linear(in_features, num_classes)  # model.head.fc ëŒ€ì‹  model.headë¡œ êµì²´
    return model


# 1. ëª¨ë¸ ì •ì˜: ConvNeXtë¥¼ ë² ì´ìŠ¤ë¼ì¸ìœ¼ë¡œ í•˜ì—¬ ìµœì¢… classification headë¥¼ 23ê°œ í´ë˜ìŠ¤ë¡œ ë³€ê²½í•©ë‹ˆë‹¤.
class Sejin(nn.Module):
    def __init__(self, base_model_name, sub_model_name, feature_num=128, num_classes=23, pretrained=True):
        super(Sejin, self).__init__()
        # Base model: classifier head ì œê±° (num_classes=0)
        self.base_model = timm.create_model(base_model_name, pretrained=pretrained, num_classes=0)
        in_features_base = self.base_model.num_features  # ê¸°ë³¸ feature dimension (ì˜ˆ: 768 í˜¹ì€ ê·¸ ì´ìƒ)
        # ë³„ë„ì˜ head: base modelì˜ featureë¥¼ feature_num ì°¨ì›ìœ¼ë¡œ ë³€í™˜
        self.base_model_head = nn.Linear(in_features_base, feature_num)

        ## Sub model (Swin Transformer): classifier head ì œê±°
        self.sub_model = timm.create_model(sub_model_name, pretrained=pretrained, num_classes=0)
        in_features_sub = self.sub_model.num_features
        ## ë³„ë„ì˜ head: sub modelì˜ featureë¥¼ feature_num ì°¨ì›ìœ¼ë¡œ ë³€í™˜
        self.sub_model_head = nn.Linear(in_features_sub, feature_num)

        # ìµœì¢… classifier: ë‘ ëª¨ë¸ì˜ featureë¥¼ ê²°í•© í›„ ë¶„ë¥˜ (23ê°œ í´ë˜ìŠ¤)
        self.classifier = nn.Sequential(
            nn.Linear(feature_num * 2, feature_num),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(feature_num, num_classes)
        )

    def forward(self, x):
        # Base model (ConvNeXt): ë³´í†µ 4D í…ì„œ ë°˜í™˜, global pooling ì ìš©
        base_features = self.base_model.forward_features(x)  # shape: (B, C, H, W) ì˜ˆìƒ
        if base_features.dim() == 4:
            base_features = F.adaptive_avg_pool2d(base_features, 1)
            base_features = torch.flatten(base_features, 1)  # (B, in_features_base)
        # ë§Œì•½ ì´ë¯¸ 2Dë¼ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
        feat1 = self.base_model_head(base_features)  # (B, feature_num)

        # Sub model (Swin Transformer): ë³´í†µ 3D í…ì„œ ë°˜í™˜, shape: (B, num_tokens, embed_dim)
        sub_features = self.sub_model.forward_features(x)
        if sub_features.dim() == 4:
            # í† í° ì°¨ì›(dim=1)ì— ëŒ€í•´ í‰ê· ì„ ë‚´ì–´ (B, embed_dim)ë¡œ ë³€í™˜
            sub_features = sub_features.mean(dim=1)
            sub_features = sub_features.mean(dim=1)
        feat2 = self.sub_model_head(sub_features)  # (B, feature_num)

        # ë‘ ëª¨ë¸ì˜ feature ê²°í•© í›„ ìµœì¢… ë¶„ë¥˜
        combined_features = torch.cat([feat1, feat2], dim=1)
        output = self.classifier(combined_features)
        return output
    

class Seungyeon(nn.Module):
    """
    CNN Branch (EfficientNet ë˜ëŠ” ConvNeXt)ì™€ ViT Branchì˜ ì¤‘ê°„ íŠ¹ì§•ì„ ìœµí•©í•˜ëŠ” ëª¨ë¸.
    ë‘ branchì˜ íŠ¹ì§•ì„ ê°ê° adapterë¥¼ ê±°ì³ 512 ì°¨ì›ìœ¼ë¡œ ë§ì¶”ê³ ,
    ê³µê°„ì ìœ¼ë¡œ ê²°í•©í•œ ë’¤ ì¶”ê°€ convolutionì„ í†µí•´ ìµœì¢… ë¶„ë¥˜ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    """
    def __init__(self, cnn_type='efficientb0', num_classes=23):
        """
        Args:
            cnn_type (str): 'efficientb0' ë˜ëŠ” 'convnext' ë“±, ì‚¬ìš©í•  CNN ëª¨ë¸ ì§€ì •.
            num_classes (int): ë¶„ë¥˜í•  í´ë˜ìŠ¤ ìˆ˜.
        """
        super(Seungyeon, self).__init__()
        
        # CNN Branch ì´ˆê¸°í™” (EfficientNet ë˜ëŠ” ConvNeXt)
        if 'efficient' in cnn_type.lower():
            self.cnn_branch = enet(model_name=cnn_type, num_classes=num_classes)
            # EfficientNetì˜ ê²½ìš°, ë§ˆì§€ë§‰ convolution blockì˜ ì¶œë ¥ ì±„ë„ ìˆ˜ (ì˜ˆì‹œ: EfficientNet B0ëŠ” ì•½ 1280)
            cnn_out_channels = 1280  
        elif 'convnext' in cnn_type.lower():
            self.cnn_branch = convnext(num_classes=num_classes)
            # ConvNeXtì˜ ê²½ìš°, ë§ˆì§€ë§‰ stageì˜ ì¶œë ¥ ì±„ë„ ìˆ˜ (ì˜ˆì‹œ: 1024)
            cnn_out_channels = 1024
        else:
            raise ValueError("ì§€ì›í•˜ì§€ ì•ŠëŠ” cnn_typeì…ë‹ˆë‹¤. (efficient ë˜ëŠ” convnext ì‚¬ìš©)")
        
        # ViT Branch ì´ˆê¸°í™”  
        # vit() í•¨ìˆ˜ëŠ” (ëª¨ë¸, feature_extractor) íŠœí”Œì„ ë°˜í™˜í•œë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤.
        self.vit_branch, self.feature_extractor = vit(num_classes=num_classes)
        # ì¼ë°˜ì ì¸ ViT ë² ì´ìŠ¤ ëª¨ë¸ì˜ ì„ë² ë”© ì°¨ì› (ì˜ˆì‹œ: 768)
        vit_feature_dim = 768
        
        # ê° branchì˜ ì¤‘ê°„ íŠ¹ì§•ì„ 512 ì°¨ì›(ì±„ë„)ìœ¼ë¡œ ë§ì¶”ê¸° ìœ„í•œ adapter
        self.cnn_adapter = nn.Conv2d(in_channels=cnn_out_channels, out_channels=512, kernel_size=1)
        self.vit_adapter = nn.Linear(vit_feature_dim, 512)
        
        # Fusion Module: ë‘ branchì˜ adapterëœ íŠ¹ì§•ì„ ì±„ë„ ë°©í–¥ìœ¼ë¡œ ê²°í•© í›„ ì¶”ê°€ convolution ì ìš©
        # ìµœì¢… ê²°í•©ëœ ì±„ë„ ìˆ˜ëŠ” 512*2=1024
        self.fusion_conv = nn.Conv2d(in_channels=1024, out_channels=512, kernel_size=3, padding=1)
        
        # ìµœì¢… ë¶„ë¥˜ í—¤ë“œ: Global Average Pooling í›„ Fully Connected layer
        self.classifier = nn.Sequential(
            nn.AdaptiveAvgPool2d(1),
            nn.Flatten(),
            nn.Linear(512, num_classes)
        )
    
    def forward(self, x):
        # CNN Branch ì²˜ë¦¬
        cnn_features = self.cnn_branch.extract_features(x) # [B, cnn_out_channels, H, W]
        cnn_features = self.cnn_adapter(cnn_features)  # [B, 512, H, W]
        
        # ViT Branch ì²˜ë¦¬
        vit_out = self.vit_branch(x, output_hidden_states=True)
        vit_tokens = vit_out.hidden_states[-1] # shape: [B, N, vit_feature_dim]
        vit_global = vit_tokens.mean(dim=1) # [B, vit_feature_dim]
        vit_features = self.vit_adapter(vit_global) # [B, 512]
        B, _, H, W = cnn_features.size() 
        vit_features = vit_features.unsqueeze(-1).unsqueeze(-1).expand(B, 512, H, W)
        
        # Fusion
        fused_features = torch.cat([cnn_features, vit_features], dim=1) # [B, 1024, H, W]
        fused_features = self.fusion_conv(fused_features) # [B, 512, H, W]
        
        # Classification
        out = self.classifier(fused_features) # [B, num_classes]
        return out    
    

# Moblie Net
def mobilenet(num_classes=23):
    # ì‚¬ì „ í•™ìŠµëœ MobileNet V2 ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
    model = models.mobilenet_v2(pretrained=True)
    
    # MobileNet V2ì˜ ë§ˆì§€ë§‰ ì±„ë„ í¬ê¸° (ì¼ë°˜ì ìœ¼ë¡œ 1280)
    last_channel = model.last_channel  # ë˜ëŠ” 1280ë¡œ ì§ì ‘ ì§€ì • ê°€ëŠ¥
    
    # classifierë¥¼ ìˆ˜ì •í•˜ì—¬ num_classesì— ë§ê²Œ ë³€ê²½
    # ì›ë˜ classifier: Sequential(Dropout(0.2), Linear(1280, 1000))
    model.classifier[1] = nn.Linear(last_channel, num_classes)
    
    return model    


# ì„¸ì§„ë‹˜ ëª¨ë¸ ì›ë³¸
class SkinDiseaseClassifier(nn.Module):
    def __init__(self, base_model_name, sub_model_name, feature_num=128, num_classes=23, pretrained=True):
        super(SkinDiseaseClassifier, self).__init__()
        # Base model: classifier head ì œê±° (num_classes=0)
        self.base_model = timm.create_model(base_model_name, pretrained=pretrained, num_classes=0)
        in_features_base = self.base_model.num_features  # ê¸°ë³¸ feature dimension (ì˜ˆ: 768 í˜¹ì€ ê·¸ ì´ìƒ)
        # ë³„ë„ì˜ head: base modelì˜ featureë¥¼ feature_num ì°¨ì›ìœ¼ë¡œ ë³€í™˜
        self.base_model_head = nn.Linear(in_features_base, feature_num)

        ## Sub model (Swin Transformer): classifier head ì œê±°
        self.sub_model = timm.create_model(sub_model_name, pretrained=pretrained, num_classes=0)
        in_features_sub = self.sub_model.num_features
        ## ë³„ë„ì˜ head: sub modelì˜ featureë¥¼ feature_num ì°¨ì›ìœ¼ë¡œ ë³€í™˜
        self.sub_model_head = nn.Linear(in_features_sub, feature_num)

        # ìµœì¢… classifier: ë‘ ëª¨ë¸ì˜ featureë¥¼ ê²°í•© í›„ ë¶„ë¥˜ (23ê°œ í´ë˜ìŠ¤)
        self.classifier = nn.Sequential(
            nn.Linear(feature_num * 2, feature_num),
            nn.ReLU(),
            # nn.Dropout(0.5),
            nn.Linear(feature_num, num_classes)
        )

    def forward(self, x):
        # Base model (ConvNeXt): ë³´í†µ 4D í…ì„œ ë°˜í™˜, global pooling ì ìš©
        base_features = self.base_model.forward_features(x)  # shape: (B, C, H, W) ì˜ˆìƒ
        if base_features.dim() == 4:
            base_features = F.adaptive_avg_pool2d(base_features, 1)
            base_features = torch.flatten(base_features, 1)  # (B, in_features_base)
            #base_features = base_features.mean(dim=1)  # (B, in_features_base)
            #print(base_features.shape)
            #base_features = base_features.mean(dim=2)  # (B, in_features_base)
            #print(base_features.shape)
            #base_features = base_features.mean(dim=2)  # (B, in_features_base)
            #print(base_features.shape)

        # ë§Œì•½ ì´ë¯¸ 2Dë¼ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
        feat1 = self.base_model_head(base_features)  # (B, feature_num)

        # Sub model (Swin Transformer): ë³´í†µ 3D í…ì„œ ë°˜í™˜, shape: (B, num_tokens, embed_dim)
        sub_features = self.sub_model.forward_features(x)
        if sub_features.dim() == 4:
            #print(sub_features.shape)
            #sub_features = F.adaptive_avg_pool2d(sub_features.transpose(1, 3), 1)
            #print(sub_features.shape)
            #sub_features = torch.flatten(sub_features, 1)
            #print(sub_features.shape)
            # í† í° ì°¨ì›(dim=1)ì— ëŒ€í•´ í‰ê· ì„ ë‚´ì–´ (B, embed_dim)ë¡œ ë³€í™˜
            sub_features = sub_features.mean(dim=1)
            #print(sub_features.shape)
            sub_features = sub_features.mean(dim=1)
            #print(sub_features.shape)
        feat2 = self.sub_model_head(sub_features)  # (B, feature_num)

        # ë‘ ëª¨ë¸ì˜ feature ê²°í•© í›„ ìµœì¢… ë¶„ë¥˜
        combined_features = torch.cat([feat1, feat2], dim=1)
        output = self.classifier(combined_features)
        return output

# Residual Block ì •ì˜
class ResidualBlock(nn.Module):
    def __init__(self, in_channels, out_channels, downsample=False):
        super(ResidualBlock, self).__init__()
        stride = 2 if downsample else 1

        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(out_channels)
        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(out_channels)

        self.shortcut = None
        if downsample or in_channels != out_channels:
            self.shortcut = nn.Sequential(
                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),
                nn.BatchNorm2d(out_channels)
            )

    def forward(self, x):
        identity = x if self.shortcut is None else self.shortcut(x)
        out = F.relu(self.bn1(self.conv1(x)))
        out = self.bn2(self.conv2(out))
        out += identity  # Skip connection (Add operation)
        return F.relu(out)

# ì „ì²´ ëª¨ë¸ ì •ì˜
class NIADermaNet(nn.Module):
    def __init__(self, num_classes=33):
        super(NIADermaNet, self).__init__()
        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)
        self.bn1 = nn.BatchNorm2d(64)
        self.relu = nn.ReLU()
        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)

        # ResNetê³¼ ë¹„ìŠ·í•œ ë¸”ë¡ êµ¬ì¡°
        self.layer1 = self._make_layer(64, 64, num_blocks=2)
        self.layer2 = self._make_layer(64, 128, num_blocks=2, downsample=True)
        self.layer3 = self._make_layer(128, 256, num_blocks=2, downsample=True)
        self.layer4 = self._make_layer(256, 512, num_blocks=2, downsample=True)

        self.global_avg_pool = nn.AdaptiveAvgPool2d(1)  # GlobalAveragePool
        self.flatten = nn.Flatten()  # Flatten
        self.fc = nn.Linear(512, num_classes)  # Gemm (FC Layer)

    def _make_layer(self, in_channels, out_channels, num_blocks, downsample=False):
        layers = [ResidualBlock(in_channels, out_channels, downsample)]
        for _ in range(1, num_blocks):
            layers.append(ResidualBlock(out_channels, out_channels))
        return nn.Sequential(*layers)

    def forward(self, x):
        x = self.relu(self.bn1(self.conv1(x)))
        x = self.maxpool(x)

        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        x = self.layer4(x)

        x = self.global_avg_pool(x)
        x = self.flatten(x)
        x = self.fc(x)

        return x


class FPN_Swin(nn.Module):
    def __init__(self, num_classes=23):
        super(FPN_Swin, self).__init__()

        # 1ï¸ Swin Transformer as Feature Extractor (Backbone)
        self.swin = timm.create_model("swin_base_patch4_window7_224", pretrained=True, features_only=True)

        # Swin Transformerì˜ Feature Map ì±„ë„ í¬ê¸°
        self.swin_channels = [128, 256, 512, 1024]  # Swin Transformerì˜ ê° Stage ì¶œë ¥ ì±„ë„

        # 2ï¸ Feature Pyramid Network (FPN)
        self.fpn = ops.FeaturePyramidNetwork(
            in_channels_list=self.swin_channels,  # Swin Transformerì—ì„œ ì¶”ì¶œëœ Feature Mapì„ ì…ë ¥
            out_channels=256
        )

        # 3ï¸ Classification Layer
        self.final_fc = nn.Linear(256, num_classes)  # ìµœì¢… Feature Mapì„ ë¶„ë¥˜ê¸°ì™€ ì—°ê²°

    def forward(self, x):
        #  1. Swin Transformer Feature Extraction
        swin_features = self.swin(x)  # Swin Transformerì˜ Feature Map ê°€ì ¸ì˜¤ê¸°

        #  2. FPN ì…ë ¥ ìƒì„±
        fpn_inputs = collections.OrderedDict()
        for i, feature in enumerate(swin_features):
            fpn_inputs[str(i)] = feature.permute(0, 3, 1, 2)  # (B, H, W, C) â†’ (B, C, H, W)

        #  3. FPN ì ìš©
        fpn_output = self.fpn(fpn_inputs)  # FPNì„ í†µí•´ Multi-Scale Feature Map ìƒì„±

        #  4. ìµœì¢… Feature Map ì‚¬ìš© (ê°€ì¥ ì‘ì€ í•´ìƒë„ Feature)
        last_feature = fpn_output["3"]  # Swin Transformerì˜ ë§ˆì§€ë§‰ Feature Map ì‚¬ìš©

        #  5. Global Average Pooling (GAP)
        gap_feature = torch.mean(last_feature, dim=[2, 3])  # GAP ì ìš©í•˜ì—¬ 1D ë²¡í„° ìƒì„±

        #  6. Classification
        output = self.final_fc(gap_feature)  # FC Layerë¥¼ í†µê³¼í•˜ì—¬ ìµœì¢… í´ë˜ìŠ¤ ì˜ˆì¸¡

        return output
    

class MultiScaleFPN(nn.Module):
    def __init__(self, in_channels_list, out_channels=256, dropout=0.4):
        super(MultiScaleFPN, self).__init__()

        # FPN 0 (Local Features)
        self.fpn0 = ops.FeaturePyramidNetwork(
            in_channels_list=in_channels_list, out_channels=out_channels
        )
        self.fpn0_convs = nn.ModuleList([
            nn.Sequential(
                nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, dilation=1),
                nn.ReLU(inplace=True),
                nn.BatchNorm2d(out_channels),
                nn.Dropout(dropout)
                ) for _ in range(len(in_channels_list))
        ])

        # FPN 1 (Mid Level Features)
        self.fpn1 = ops.FeaturePyramidNetwork(
            in_channels_list=in_channels_list, out_channels=out_channels
        )
        self.fpn1_convs = nn.ModuleList([
            nn.Sequential(
                nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=2, padding=2, dilation=2),
                nn.ReLU(inplace=True),
                nn.BatchNorm2d(out_channels),
                nn.Dropout(dropout)
            )
            for _ in range(len(in_channels_list))
        ])

        # FPN 2 (Global Features, stride=2 + stride=4 í˜¼í•©)
        self.fpn2 = ops.FeaturePyramidNetwork(
            in_channels_list=in_channels_list, out_channels=out_channels
        )
        self.fpn2_convs1 = nn.ModuleList([
            nn.Sequential(
                nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=2, padding=4, dilation=4),
                nn.ReLU(inplace=True),
                nn.BatchNorm2d(out_channels),
                nn.Dropout(dropout)
            )
            for _ in range(len(in_channels_list))
        ])
        self.fpn2_convs2 = nn.ModuleList([
            nn.Sequential(
                nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=4, padding=6, dilation=6),
                nn.ReLU(inplace=True),
                nn.BatchNorm2d(out_channels),
                nn.Dropout(dropout)
            )
            for _ in range(len(in_channels_list))
        ])

    def forward(self, features):
        # FPN 0 (Local Features)
        fpn0_features = self.fpn0(features)
        fpn0_outs = {k: self.fpn0_convs[int(k)](v) for k, v in fpn0_features.items()}

        # FPN 1 (Mid-Level Features)
        fpn1_features = self.fpn1(features)
        fpn1_outs = {k: self.fpn1_convs[int(k)](v) for k, v in fpn1_features.items()}

        # FPN 2 (Global Features with stride=2 and stride=4)
        fpn2_features = self.fpn2(features)
        fpn2_outs1 = {k: self.fpn2_convs1[int(k)](v) for k, v in fpn2_features.items()}
        fpn2_outs2 = {k: self.fpn2_convs2[int(k)](v) for k, v in fpn2_features.items()}

        # stride=2ì™€ stride=4ë¥¼ í•©ì¹˜ê¸° ìœ„í•´ Interpolation ìˆ˜í–‰
        fpn2_final_outs = {
            k: (fpn2_outs1[k] + F.interpolate(fpn2_outs2[k], size=fpn2_outs1[k].shape[2:], mode="bilinear", align_corners=False)) / 2
            for k in fpn2_outs1.keys()
        }

        return fpn0_outs, fpn1_outs, fpn2_final_outs


class ConvNeXt_FPN(nn.Module):
    def __init__(self, num_classes=23, out_channels=256, dropout=0.4):
        super(ConvNeXt_FPN, self).__init__()

        self.backbone = timm.create_model("convnext_base", pretrained=True, features_only=True)
        self.in_channels_list = self.backbone.feature_info.channels()  # [128, 256, 512, 1024]

        # Multi-Scale FPN ì ìš©
        self.multi_scale_fpn = MultiScaleFPN(in_channels_list=self.in_channels_list, out_channels=out_channels)

        self.final = nn.Sequential(
            nn.Linear(out_channels * len(self.in_channels_list) * 3, 2048),
            nn.ReLU(inplace=True),
            nn.LayerNorm(2048),
            nn.Dropout(dropout),
            # nn.Linear(2048, 1024),
            # nn.ReLU(inplace=True),
            # nn.LayerNorm(1024),
            # nn.Dropout(dropout),
            # nn.Linear(1024, 256),
            # nn.ReLU(inplace=True),
            # nn.LayerNorm(256),
            # nn.Dropout(dropout),
            # nn.Linear(256, num_classes)
            nn.Linear(2048, num_classes)
        )
        
        # Classification Layer
        self.fc1 = nn.Linear(out_channels * len(self.in_channels_list) * 3, 1024)  # out_channel * ([128, 256, 512, 1024])ê°œìˆ˜ * 3(fpn ê°œìˆ˜)
        self.norm = nn.LayerNorm(len(self.in_channels_list))

        self.final_fc = nn.Linear(len(self.in_channels_list), num_classes)

    def forward(self, x):
        # ConvNeXt Feature ì¶”ì¶œ
        features = self.backbone(x)

        # Feature Mapì„ ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ë³€í™˜
        feature_dict = {str(i): features[i] for i in range(len(features))}

        # Multi-Scale FPN ì ìš©
        fpn0_outs, fpn1_outs, fpn2_outs = self.multi_scale_fpn(feature_dict)

        # 3ê°œì˜ FPN Featureë¥¼ Global Average Pooling (GAP) í›„ Concatenation
        fpn0_gap = torch.cat([torch.mean(fpn0_outs[k], dim=[2, 3]) for k in fpn0_outs.keys()], dim=1)
        fpn1_gap = torch.cat([torch.mean(fpn1_outs[k], dim=[2, 3]) for k in fpn1_outs.keys()], dim=1)
        fpn2_gap = torch.cat([torch.mean(fpn2_outs[k], dim=[2, 3]) for k in fpn2_outs.keys()], dim=1)

        # Feature Concatenation
        merged_feature = torch.cat([fpn0_gap, fpn1_gap, fpn2_gap], dim=1)

        # Classification
        output = self.final(merged_feature)

        return output
    

class FPN_Swin2(nn.Module):
    def __init__(self, num_classes=23):
        super(FPN_Swin2, self).__init__()
        self.swin = timm.create_model("swin_tiny_patch4_window7_224", pretrained=True, features_only=True)

        # Swin Transformerì—ì„œ ì„ íƒí•  Feature Map ì±„ë„ í¬ê¸° (0, 2ë²ˆ ì¸ë±ìŠ¤ -> batchê°€ 64ì¼ ê²½ìš° í„°ì§)
        # self.selected_layers = [0, 2]  # ì‚¬ìš©í•  feature index
        # self.swin_channels = [128, 512]  # Swin Transformerì˜ í•´ë‹¹ Stage ì¶œë ¥ ì±„ë„
        self.selected_layers = [1]
        self.swin_channels = [192]

        self.fpn = ops.FeaturePyramidNetwork(
            in_channels_list=self.swin_channels,  
            out_channels=256
        )

        self.final_fc = nn.Linear(256, num_classes) 

    def forward(self, x):
        swin_features = self.swin(x)  # Swin Transformerì˜ Feature Map ê°€ì ¸ì˜¤ê¸°

        selected_features = {str(i): swin_features[idx].permute(0, 3, 1, 2) 
                             for i, idx in enumerate(self.selected_layers)}

        fpn_output = self.fpn(selected_features)  # FPNì„ í†µí•´ Multi-Scale Feature Map ìƒì„±
        last_feature = fpn_output[str(len(self.selected_layers) - 1)]  # ì„ íƒëœ ë§ˆì§€ë§‰ feature ì‚¬ìš©
        gap_feature = torch.mean(last_feature, dim=[2, 3])  # GAP ì ìš©í•˜ì—¬ 1D ë²¡í„° ìƒì„±

        output = self.final_fc(gap_feature)  # FC Layerë¥¼ í†µê³¼í•˜ì—¬ ìµœì¢… í´ë˜ìŠ¤ ì˜ˆì¸¡

        return output