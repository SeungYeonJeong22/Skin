import torch
import numpy as np
import random
import os
from tqdm import tqdm
from datetime import datetime
import matplotlib.pyplot as plt
import cv2
from torch.cuda.amp import GradScaler, autocast
import torch.nn as nn
import torch.nn.functional as F
from sklearn.metrics import precision_score

from warnings import filterwarnings
filterwarnings('ignore', category=UserWarning, module='torch')
filterwarnings('ignore', category=FutureWarning, module='torch')

try:
    import torchmetrics
except ImportError:
    import subprocess
    import sys
    print("üì¶ timm Ìå®ÌÇ§ÏßÄÍ∞Ä ÏóÜÏñ¥ÏÑú ÏÑ§ÏπòÌï©ÎãàÎã§...")    
    subprocess.check_call([sys.executable, "-m", "pip", "install", "torchmetrics"])
    import torchmetrics



def current_time():
    return datetime.now().strftime("%m%d_%H%M")

# check the directory to save weights.pt
def createFolder(directory):
    try:
        if not os.path.exists(directory):
            os.makedirs(directory)
    except Exception as e:
        print('Error')
createFolder('./models')

# fix seed for reproducibility
def seed(seed):
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True # non-deterministic
    torch.backends.cudnn.benchmark = False 
    np.random.seed(seed)
    random.seed(seed)
    

# get current lr
def get_lr(opt):
    for param_group in opt.param_groups:
        return param_group['lr']


# OOD Í∞êÏßÄ Ìï®Ïàò (Softmax ÌôïÎ•† Í∏∞Î∞ò)
def is_unknown_sample(logits, top_k=3, threshold=0.6):
    probs = torch.softmax(logits, dim=1)
    
    topk_probs, _ = torch.topk(probs, k=top_k, dim=1)
    topk_sum = topk_probs.sum(dim=1)
    
    mask = topk_sum < threshold
    return mask # True: Unknown, False: Known


# # Í∞ÄÏ§ëÏπòÎ•º Î∞òÏòÅÌïú Ï†ïÌôïÎèÑ Í≥ÑÏÇ∞ Ìï®Ïàò (ISIC 2019 Îç∞Ïù¥ÌÑ∞ÏÖã Ï†ÅÏö©)
# def weighted_accuracy(pred, target, img_names, test_gt):
#     # Unknown(8) ÌÅ¥ÎûòÏä§ Ï†úÍ±∞ÌïòÏó¨ ÌèâÍ∞Ä
#     valid_mask = target != 8  # Unknown(8) Ï†úÏô∏
#     pred = pred[valid_mask]
#     target = target[valid_mask]

#     if len(target) == 0:  # Î™®Îì† ÏÉòÌîåÏù¥ UnknownÏù¥Î©¥ 0 Î∞òÌôò
#         return 0.0, 0

#     # `torchmetrics.Accuracy`Î•º Ïò¨Î∞îÎ•∏ ÎîîÎ∞îÏù¥Ïä§Î°ú Ïù¥Îèô
#     metric_acc = torchmetrics.Accuracy(task="multiclass", num_classes=8, average="weighted", top_k=1).to(output.device)

#     acc = metric_acc(pred, target).item()  # GPUÏóêÏÑú CPUÎ°ú Í∞ÄÏ†∏ÏôÄÏÑú float Í∞í Î∞òÌôò
#     batch_weight_sum = len(target)  # UnknownÏùÑ Ï†úÏô∏Ìïú ÏÉòÌîå ÏàòÎ•º Í∞ÄÏ§ëÏπòÎ°ú ÏÇ¨Ïö©

#     # return acc * batch_weight_sum, batch_weight_sum  # (Ï†ïÌôïÎèÑ * Í∞ÄÏ§ëÏπò, Ï¥ù Í∞ÄÏ§ëÏπò)
#     return acc


# # calculate the accuracy per mini-batch
# def accuracy(output, target):
#     pred = output.argmax(1, keepdim=True)
#     corrects = pred.eq(target.view_as(pred)).sum().item()
#     return corrects / target.size(0)


def eval_metric(output, target, num_classes, isic_flag=False):
    prob = torch.softmax(output, dim=1)
    max_prob, pred = torch.max(prob, dim=1)
    # pred = torch.softmax(output, dim=1).argmax(1, keepdim=True).squeeze(1)
    target = target.view_as(pred)
    
    # ISIC Dataset
    if isic_flag:
        # unknown post process
        # unknown_mask = is_unknown_sample(output, top_k=1, threshold=0.3)
        # pred[unknown_mask] = 8
        pass

        # print(f"Unknown mask Ï†ÅÏö©Îêú ÏÉòÌîå Ïàò: {unknown_mask.sum().item()}")
        # print("Unique predicted labels:", torch.unique(pred))
        # print(f"Predicted class distribution: {torch.bincount(pred)}")
        
        # metric_acc = torchmetrics.Accuracy(task="multiclass", num_classes=9, average="weighted", top_k=1).to(output.device)
        # metric_precision = torchmetrics.Precision(task = "multiclass", num_classes=9, average="weighted", top_k=1).to(output.device)
        # metric_recall = torchmetrics.Recall(task = "multiclass", num_classes=9, average="weighted", top_k=1).to(output.device)
        # metric_f1 = torchmetrics.F1Score(task = "multiclass", num_classes=9, average="weighted", top_k=1).to(output.device)

    # else:
    metric_acc = torchmetrics.Accuracy(task="multiclass", num_classes=num_classes, average="weighted").to(output.device)
    # metric_precision = torchmetrics.Precision(task = "multiclass", num_classes=num_classes, average="weighted").to(output.device)
    metric_precision = torchmetrics.Precision(task="multiclass", num_classes=num_classes, average="weighted").to("cpu")
    metric_recall = torchmetrics.Recall(task = "multiclass", num_classes=num_classes, average="weighted").to(output.device)
    metric_f1 = torchmetrics.F1Score(task = "multiclass", num_classes=num_classes, average="weighted").to(output.device) 

    acc = metric_acc(pred, target).item()
    if acc == np.nan:
        pass
    # recall = metric_recall(pred, target).item()
    # f1_score = metric_f1(pred, target).item()

    # metric_precision.update(pred.cpu(), target.cpu())  
    # precision = metric_precision.compute().item()

    sklearn_precision = precision_score(target.cpu().numpy(), pred.cpu().numpy(), average="weighted", zero_division=0)

    # return prob, max_prob, pred, target, acc, precision, recall, f1_score
    return prob, max_prob, pred, target, acc

# calculate the loss and accuracy per epoch
def loss_epoch(model, model_name, epoch, loss_func, dataset_dl, int2label=None, opt=None, device='cpu', mode='train', training_record_flag='false'):
    import torchmetrics
    from tqdm import tqdm
    from torch.cuda.amp import autocast

    running_loss = 0.0
    running_acc = 0.0
    len_data = len(dataset_dl.dataset)

    metric_acc = torchmetrics.Accuracy(task="multiclass", num_classes=dataset_dl.dataset.num_classes, average="weighted", top_k=1).to(device)
    is_train = opt is not None

    record_list = []

    for idx, (xb, yb, img_name) in enumerate(tqdm(dataset_dl, desc=f"Processing {mode} batches")):
        xb = xb.to(device)
        yb = yb.to(device)

        with autocast():
            output = model(xb)

            if model_name.lower() == 'vit':
                logits = output.logits if hasattr(output, 'logits') else output
            elif model_name.lower().__contains__("swin_transformer"):
                logits = output
                if output.ndim == 4:
                    output = output.permute(0, 3, 1, 2)
                    logits = torch.nn.functional.adaptive_avg_pool2d(output, 1).flatten(1)
            else:
                logits = output

            loss_b = loss_func(logits, yb)
            acc_b = metric_acc(logits, yb).item()

        if is_train:
            opt.zero_grad()
            loss_b.backward()
            opt.step()

        running_loss += loss_b.item() * xb.size(0)
        running_acc += acc_b * xb.size(0)

        if training_record_flag and mode == 'train':
            probs = torch.softmax(logits.float(), dim=1).detach().cpu()
            preds = torch.argmax(probs, dim=1)

            for i in range(len(yb)):
                record_list.append({
                    'image': os.path.basename(img_name[i]),
                    'true_label': int2label[str(yb[i].item())],
                    'predicted_label': int2label[str(preds[i].item())],
                    'probability': f"{probs[i, preds[i]].item()}.:4f"
                })

    loss = running_loss / len_data
    acc = running_acc / len_data

    return loss, acc, record_list


def draw_plot(num_epochs, loss_hist, metric_hist):
    os.makedirs('imgs/plots', exist_ok=True)
    # Plot train-val loss
    plt.title('Train-Val Loss')
    plt.plot(range(1, num_epochs+1), loss_hist['train'], label='train')
    plt.plot(range(1, num_epochs+1), loss_hist['val'], label='val')
    plt.ylabel('Loss')
    plt.xlabel('Training Epochs')
    plt.legend()
    plt.savefig('imgs/plots/train_val_loss.png')

    # plot train-val accuracy
    plt.title('Train-Val Accuracy')
    plt.plot(range(1, num_epochs+1), metric_hist['train'], label='train')
    plt.plot(range(1, num_epochs+1), metric_hist['val'], label='val')
    plt.ylabel('Accuracy')
    plt.xlabel('Training Epochs')
    plt.legend()
    plt.savefig('imgs/plots/train_val_accuracy.png')

# Grad-CAM
def grad_cam(model, img_tensor, target_layer, class_idx=None):
    model.eval()
    img_tensor = img_tensor.unsqueeze(0)  # Î∞∞Ïπò Ï∞®Ïõê Ï∂îÍ∞Ä

    # Feature Î∞è Gradient Ï†ÄÏû•ÏùÑ ÏúÑÌïú Î¶¨Ïä§Ìä∏
    features = []
    gradients = []

    # Forward hook (ÌäπÏßï Îßµ Ï†ÄÏû•)
    def forward_hook(module, input, output):
        features.append(output)

    # Backward hook (Gradient Ï†ÄÏû•)
    def backward_hook(module, grad_in, grad_out):
        gradients.append(grad_out[0])

    # Hook Îì±Î°ù
    handle_forward = target_layer.register_forward_hook(forward_hook)
    handle_backward = target_layer.register_backward_hook(backward_hook)

    # Forward propagation
    output = model(img_tensor)
    
    # Hook Ï†úÍ±∞ (Î©îÎ™®Î¶¨ ÎàÑÏàò Î∞©ÏßÄ)
    handle_forward.remove()
    handle_backward.remove()

    if class_idx is None:
        class_idx = torch.argmax(output, dim=1).item()

    # Backward propagation
    model.zero_grad()
    class_score = output[0, class_idx]
    class_score.backward()

    # GradientÍ∞Ä Ï†ÄÏû•ÎêòÏßÄ ÏïäÏùÄ Í≤ΩÏö∞ ÏòàÏô∏ Ï≤òÎ¶¨
    if len(gradients) == 0 or len(features) == 0:
        raise RuntimeError("Gradients or Features are not captured. Check target_layer.")

    # Gradients Î∞è Feature Map Í∞ÄÏ†∏Ïò§Í∏∞
    gradients = gradients[0]  # [batch, channels, height, width]
    features = features[0][0]  # [channels, height, width]

    # Gradient ÌèâÍ∑† ÌíÄÎßÅ
    pooled_gradients = torch.mean(gradients, dim=[0, 2, 3], keepdim=True)
    pooled_gradients = pooled_gradients.view(features.shape[0], 1, 1)

    # Feature Map Í∞ÄÏ§ëÏπò Ï†ÅÏö©
    features *= pooled_gradients

    # Heatmap ÏÉùÏÑ±
    heatmap = torch.mean(features, dim=0).cpu().detach().numpy()
    heatmap = np.maximum(heatmap, 0)  # ReLU Ï†ÅÏö© (ÏùåÏàò Í∞í Ï†úÍ±∞)
    heatmap /= (np.max(heatmap) + 1e-8)  # Ï†ïÍ∑úÌôî (0~1) + ÏïàÏ†ïÏÑ± ÌôïÎ≥¥

    return heatmap

# def apply_heatmap(img, heatmap, alpha=0.6, colormap=cv2.COLORMAP_JET):
#     heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))
#     heatmap = np.uint8(255 * heatmap)
#     heatmap = cv2.applyColorMap(heatmap, colormap)
#     superimposed_img = cv2.addWeighted(img, 1 - alpha, heatmap, alpha, 0)
#     return superimposed_img

# HeatmapÏùÑ Ïù¥ÎØ∏ÏßÄÏóê Ï†ÅÏö©
def apply_heatmap(img, heatmap, alpha=0.6, colormap=cv2.COLORMAP_JET):
    """
    Grad-CAM heatmapÏùÑ ÏõêÎ≥∏ Ïù¥ÎØ∏ÏßÄÏóê Ï†ÅÏö©ÌïòÎäî Ìï®Ïàò.
    
    :param img: ÏõêÎ≥∏ Ïù¥ÎØ∏ÏßÄ (H, W, 3) (uint8)
    :param heatmap: Grad-CAMÏóêÏÑú ÏÉùÏÑ±Îêú heatmap (H, W) (float)
    :param alpha: heatmapÏùò Í∞ÄÏ§ëÏπò (0~1)
    :param colormap: Ï†ÅÏö©Ìï† OpenCV Ïª¨Îü¨Îßµ (Í∏∞Î≥∏Í∞í: JET)
    :return: heatmapÏù¥ Ï†ÅÏö©Îêú Ïù¥ÎØ∏ÏßÄ
    """
    # heatmapÏùÑ ÏõêÎ≥∏ Ïù¥ÎØ∏ÏßÄ ÌÅ¨Í∏∞Î°ú Î≥ÄÌôò
    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))

    # NaN Í∞í Î∞©ÏßÄ
    heatmap = np.nan_to_num(heatmap)

    # HeatmapÏùÑ uint8Î°ú Î≥ÄÌôò (0~255)
    heatmap = np.uint8(255 * heatmap)

    # Ïª¨Îü¨Îßµ Ï†ÅÏö©
    heatmap = cv2.applyColorMap(heatmap, colormap)

    # ÏõêÎ≥∏ Ïù¥ÎØ∏ÏßÄÏôÄ ÌòºÌï© (Ìà¨Î™ÖÎèÑ alpha Ï°∞Ï†à)
    if img.dtype != np.uint8:
        img = np.uint8(255 * (img - img.min()) / (img.max() - img.min()))  # 0~255Î°ú Î≥ÄÌôò

    superimposed_img = cv2.addWeighted(img, 1 - alpha, heatmap, alpha, 0)

    return superimposed_img

def save_grad_cam(img_path, model, img_tensor, target_layer, output_path, class_idx=None):
    heatmap = grad_cam(model, img_tensor, target_layer, class_idx)
    img = cv2.imread(img_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    superimposed_img = apply_heatmap(img, heatmap)
    cv2.imwrite(output_path, superimposed_img)


# Hook Ìï®Ïàò Ï†ïÏùò
def get_activation(activation, name):
    def hook(model, input, output):
        activation[name] = output.detach()
    return hook


class FocalLoss(nn.Module):
    def __init__(self, alpha=0.25, gamma=2, reduction='mean'):
        """
        Focal Loss Íµ¨ÌòÑ
        :param alpha: ÌäπÏ†ï ÌÅ¥ÎûòÏä§Ïóê Í∞ÄÏ§ëÏπòÎ•º Ï£ºÎäî ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞ (ÌÅ¥ÎûòÏä§ Î∂àÍ∑†Ìòï Ïãú Ïú†Ïö©)
        :param gamma: Ïñ¥Î†§Ïö¥ ÏÉòÌîåÏóê ÎåÄÌïú Í∞ÄÏ§ëÏπòÎ•º Ï°∞Ï†ïÌïòÎäî ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞
        :param reduction: 'mean', 'sum', 'none' Ï§ë ÏÑ†ÌÉù Í∞ÄÎä•
        """
        super(FocalLoss, self).__init__()
        self.alpha = alpha
        self.gamma = gamma
        self.reduction = reduction

    def forward(self, inputs, targets):
        """
        :param inputs: Î™®Îç∏ Ï∂úÎ†•Í∞í (logits ÌòïÌÉú) [batch_size, num_classes]
        :param targets: Ï†ïÎãµ ÎùºÎ≤® (Ï†ïÏàòÌòï) [batch_size]
        :return: Focal Loss Í∞í
        """
        ce_loss = F.cross_entropy(inputs, targets, reduction='none')  # Í∏∞Î≥∏ CE Loss Í≥ÑÏÇ∞
        pt = torch.exp(-ce_loss)  # ÏòàÏ∏° ÌôïÎ•†Í∞í Î≥ÄÌôò

        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss  # Focal Loss Ï†ÅÏö©

        if self.reduction == 'mean':
            return focal_loss.mean()
        elif self.reduction == 'sum':
            return focal_loss.sum()
        else:
            return focal_loss
        

def device_settings(args=None):
    if args:
        batch_size = args.batch_size
        num_workers = args.num_workers
    else:
        batch_size = 32
        num_workers = 4

    # Device setting + DataParallel
    if torch.cuda.is_available():
        n_gpus = torch.cuda.device_count()
        device = torch.device("cuda")
        print(f"Using CUDA ({n_gpus} GPUs): {torch.cuda.get_device_name(0)}")
    elif torch.backends.mps.is_available():
        n_gpus = 0
        device = torch.device("mps")
        print("Using MPS (Apple Silicon GPU)")
    else:
        n_gpus = 0
        device = torch.device("cpu")
        print("Using CPU")

    if n_gpus > 1:
        batch_size *= n_gpus
        num_workers *= n_gpus

    return device, n_gpus, batch_size, num_workers